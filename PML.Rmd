---
title: "Practical Machine Learning"
author: "Jo Hanna Lindsey Serato"
date: "December 11, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Introduction
This assignment aims to predict the manner in which the participants did the exercise. Random Forest, Data Tree Model, and GBM to train the input data. Random Forest turned out to have the most number of right predictions.  

### Loading the datasets

The datasets were from the project: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har


```{r loading}

library(caret)

library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(corrplot)

# set the URL for the download
urlTraining <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urlTesting  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

# download the datasets
ds_training <- read.csv(url(urlTraining))
ds_testing  <- read.csv(url(urlTesting))

```

### Cleaning the data

Data that is not available and/or has features that is not included to the testing dataset is not included in the dataset that is used for training the models. 

```{r cleaning}
features <- names(ds_testing[,colSums(is.na(ds_testing)) == 0])[8:59]
ds_training <- ds_training[,c(features,"classe")]
ds_testing <- ds_testing[,c(features,"problem_id")]

dim(ds_training)
dim(ds_testing)

```

### Separating the training and testing datasets

The training dataset is to to be 60% of the total cases as recommended in the course. 

```{r separating}
set.seed(77777)

inTrain <- createDataPartition(ds_training$classe, p=0.6, list=FALSE)
training <- ds_training[inTrain,]
testing <- ds_training[-inTrain,]

dim(training);
dim(testing)
```

### Correlation Analysis

The plot below shows that there are quite a few parameters that are correlated with each other. 

``` {r correlation}
corMatrix <- cor(training[, -53])
corrplot(corMatrix, order = "FPC", method = "color", type = "lower", 
         tl.cex = 0.8, tl.col = rgb(0, 0, 0))
```

### Prediction Models
This section describes the medthods done for each model: the cross validation part, prediction using the testing dataset, and prediction using the testing classe, and the out of sample error value. 

Sicne the Random Forest yielded the least out of sample error, random forest predictions were used in the quiz.

#### Random Forest

**Building the models**

```{r rf_build}
library(randomForest)
set.seed(7777)

rf.training=randomForest(classe~.,data=training,ntree=100, importance=TRUE)
rf.training
```

**Cross validation**
```{r rf_validation}
prediction <- predict(rf.training, testing, type = "class")
confusionMatrix(prediction, testing$classe)

```

**Prediction**
```{r rf_predict}

predictionRF <- predict(rf.training, ds_testing, type = "class")
predictionRF

```

**Out of sample Error**

```{r rfoos}
out_of_sample_error <- 1 - postResample(prediction, testing$classe)[[1]]
out_of_sample_error

```

#### Decision Tree MOdel


**Building the models**

```{r dt_build}

dt.training<- rpart(classe ~ ., data = training, method="class")
fancyRpartPlot(dt.training, sub = "")

```

**Cross validation**
```{r dt_validation}
set.seed(7777)

prediction <- predict(dt.training, testing, type = "class")
confusionMatrix(prediction, testing$classe)
```

**Prediction**
```{r dt_predict}
predictionDT <- predict(dt.training, ds_testing, type = "class")
predictionDT


```

**Out of sample Error**
```{r dtoos}

out_of_sample_error <- 1 - postResample(prediction, testing$classe)[[1]]
out_of_sample_error

```

#### Gradient Boosted Model


**Building the models **

```{r gb_build}
set.seed(12345)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
gb.training  <- train(classe ~ ., data=training, method = "gbm",
                    trControl = controlGBM, verbose = FALSE)
gb.training$finalModel
```

**Cross validation**
```{r gb_validation}
#set.seed(12345)

prediction <- predict(gb.training, testing)
confusionMatrix(prediction, testing$classe)

```

**Prediction**
```{r gb_predict}

predictionGB <- predict(gb.training, ds_testing)
predictionGB

```

**Out of sample error**
```{r gboos}
out_of_sample_error <- 1 - postResample(prediction, testing$classe)[[1]]
out_of_sample_error

```


